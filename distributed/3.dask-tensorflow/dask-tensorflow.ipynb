{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask import delayed\n",
    "from dask_tensorflow import start_tensorflow\n",
    "from distributed import Client, progress\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dask.array as da\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<from-value, shape=(55000, 784), dtype=float32, chunksize=(55000, 784)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mnist():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('mnist-data', one_hot=True)\n",
    "    return mnist.train.images, mnist.train.labels\n",
    "\n",
    "datasets = [delayed(get_mnist)() for i in range(1)]\n",
    "images = [d[0] for d in datasets]\n",
    "labels = [d[1] for d in datasets]\n",
    "\n",
    "images = [da.from_delayed(im, shape=(55000, 784), dtype='float32') for im in images]\n",
    "labels = [da.from_delayed(la, shape=(55000, 10), dtype='float32') for la in labels]\n",
    "\n",
    "images = da.concatenate(images, axis=0)\n",
    "labels = da.concatenate(labels, axis=0)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = client.persist([images, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b64704080>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b647d2b70>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = images[1].compute().reshape((28, 28))\n",
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.rechunk((10000, 784))\n",
    "labels = labels.rechunk((10000, 10))\n",
    "\n",
    "images = images.to_delayed().flatten().tolist()\n",
    "labels = labels.to_delayed().flatten().tolist()\n",
    "batches = [delayed([im, la]) for im, la in zip(images, labels)]\n",
    "\n",
    "batches = client.compute(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_tensorflow import start_tensorflow\n",
    "tf_spec, dask_spec = start_tensorflow(client,ps=1,worker=2,scorer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ps': ['tcp://127.0.0.1:41985'],\n",
       " 'scorer': ['tcp://127.0.0.1:33524'],\n",
       " 'worker': ['tcp://127.0.0.1:41270', 'tcp://127.0.0.1:41200']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tempfile\n",
    "import time\n",
    "from queue import Empty\n",
    "\n",
    "IMAGE_PIXELS = 28\n",
    "hidden_units = 100\n",
    "learning_rate = 0.01\n",
    "sync_replicas = False\n",
    "replicas_to_aggregate = len(dask_spec['worker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(server):\n",
    "    worker_device = \"/job:%s/task:%d\" % (server.server_def.job_name,\n",
    "                                         server.server_def.task_index)\n",
    "    task_index = server.server_def.task_index\n",
    "    is_chief = task_index == 0\n",
    "\n",
    "    with tf.device(tf.train.replica_device_setter(\n",
    "                      worker_device=worker_device,\n",
    "                      ps_device=\"/job:ps/cpu:0\",\n",
    "                      cluster=tf_spec)):\n",
    "\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "        # Variables of the hidden layer\n",
    "        hid_w = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [IMAGE_PIXELS * IMAGE_PIXELS, hidden_units],\n",
    "                stddev=1.0 / IMAGE_PIXELS),\n",
    "            name=\"hid_w\")\n",
    "        hid_b = tf.Variable(tf.zeros([hidden_units]), name=\"hid_b\")\n",
    "\n",
    "        # Variables of the softmax layer\n",
    "        sm_w = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [hidden_units, 10],\n",
    "                stddev=1.0 / math.sqrt(hidden_units)),\n",
    "            name=\"sm_w\")\n",
    "        sm_b = tf.Variable(tf.zeros([10]), name=\"sm_b\")\n",
    "\n",
    "        # Ops: located on the worker specified with task_index\n",
    "        x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n",
    "        y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "        hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n",
    "        hid = tf.nn.relu(hid_lin)\n",
    "\n",
    "        y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n",
    "        cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "\n",
    "        opt = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "        if sync_replicas:\n",
    "            if replicas_to_aggregate is None:\n",
    "                replicas_to_aggregate = num_workers\n",
    "            else:\n",
    "                replicas_to_aggregate = replicas_to_aggregate\n",
    "\n",
    "            opt = tf.train.SyncReplicasOptimizer(\n",
    "                      opt,\n",
    "                      replicas_to_aggregate=replicas_to_aggregate,\n",
    "                      total_num_replicas=num_workers,\n",
    "                      name=\"mnist_sync_replicas\")\n",
    "\n",
    "        train_step = opt.minimize(cross_entropy, global_step=global_step)\n",
    "\n",
    "        if sync_replicas:\n",
    "            local_init_op = opt.local_step_init_op\n",
    "            if is_chief:\n",
    "                local_init_op = opt.chief_init_op\n",
    "\n",
    "            ready_for_local_init_op = opt.ready_for_local_init_op\n",
    "\n",
    "            # Initial token and chief queue runners required by the sync_replicas mode\n",
    "            chief_queue_runner = opt.get_chief_queue_runner()\n",
    "            sync_init_op = opt.get_init_tokens_op()\n",
    "\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        train_dir = tempfile.mkdtemp()\n",
    "\n",
    "        if sync_replicas:\n",
    "            sv = tf.train.Supervisor(\n",
    "              is_chief=is_chief,\n",
    "              logdir=train_dir,\n",
    "              init_op=init_op,\n",
    "              local_init_op=local_init_op,\n",
    "              ready_for_local_init_op=ready_for_local_init_op,\n",
    "              recovery_wait_secs=1,\n",
    "              global_step=global_step)\n",
    "        else:\n",
    "            sv = tf.train.Supervisor(\n",
    "              is_chief=is_chief,\n",
    "              logdir=train_dir,\n",
    "              init_op=init_op,\n",
    "              recovery_wait_secs=1,\n",
    "              global_step=global_step)\n",
    "\n",
    "        sess_config = tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            log_device_placement=False,\n",
    "            device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % task_index])\n",
    "\n",
    "        # The chief worker (task_index==0) session will prepare the session,\n",
    "        # while the remaining workers will wait for the preparation to complete.\n",
    "        if is_chief:\n",
    "            print(\"Worker %d: Initializing session...\" % task_index)\n",
    "        else:\n",
    "            print(\"Worker %d: Waiting for session to be initialized...\" %\n",
    "                task_index)\n",
    "\n",
    "        sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n",
    "\n",
    "        if sync_replicas and is_chief:\n",
    "            sess.run(sync_init_op)\n",
    "            sv.start_queue_runners(sess, [chief_queue_runner])\n",
    "\n",
    "        return sess, x, y_, train_step, global_step, cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps_task():\n",
    "    with local_client() as c:\n",
    "        c.worker.tensorflow_server.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_task():\n",
    "    with local_client() as c:\n",
    "        # Scores Channel\n",
    "        scores = c.channel('scores', maxlen=10)\n",
    "\n",
    "        # Make Model\n",
    "        server = c.worker.tensorflow_server\n",
    "        sess, _, _, _, _, cross_entropy = model(c.worker.tensorflow_server)\n",
    "\n",
    "        # Testing Data\n",
    "        from tensorflow.examples.tutorials.mnist import input_data\n",
    "        mnist = input_data.read_data_sets('/tmp/mnist-data', one_hot=True)\n",
    "        test_data = {x: mnist.validation.images,\n",
    "                     y_: mnist.validation.labels}\n",
    "\n",
    "        # Main Loop\n",
    "        while True:\n",
    "            score = sess.run(cross_entropy, feed_dict=test_data)\n",
    "            scores.append(float(score))\n",
    "\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_task():\n",
    "    with local_client() as c:\n",
    "        scores = c.channel('scores')\n",
    "        num_workers = replicas_to_aggregate = len(dask_spec['worker'])\n",
    "\n",
    "        server = c.worker.tensorflow_server\n",
    "        queue = c.worker.tensorflow_queue\n",
    "\n",
    "        # Make model\n",
    "        sess, x, y_, train_step, global_step, _= model(c.worker.tensorflow_server)\n",
    "\n",
    "        # Main loop\n",
    "        while not scores or scores.data[-1] > 1000:\n",
    "            try:\n",
    "                batch = queue.get(timeout=0.5)\n",
    "            except Empty:\n",
    "                continue\n",
    "\n",
    "            train_data = {x: batch[0],\n",
    "                          y_: batch[1]}\n",
    "\n",
    "            sess.run([train_step, global_step], feed_dict=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_tasks = [client.submit(ps_task, workers=worker)\n",
    "            for worker in dask_spec['ps']]\n",
    "\n",
    "worker_tasks = [client.submit(worker_task, workers=addr, pure=False)\n",
    "                for addr in dask_spec['worker']]\n",
    "\n",
    "scorer_task = client.submit(scoring_task, workers=dask_spec['scorer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ps': ['tcp://127.0.0.1:41985'],\n",
       " 'scorer': ['tcp://127.0.0.1:33524'],\n",
       " 'worker': ['tcp://127.0.0.1:41270', 'tcp://127.0.0.1:41200']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed.worker_client import get_worker\n",
    "\n",
    "def transfer_dask_to_tensorflow(batch):\n",
    "    worker = get_worker()\n",
    "    worker.tensorflow_queue.put(batch)\n",
    "\n",
    "dump = client.map(transfer_dask_to_tensorflow, batches,\n",
    "                  workers=dask_spec['worker'], pure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
